{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MyOnlineCourses\\\\ML_Projects\\\\arabic-digits-recognition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreparationConfig:\n",
    "    root_dir: Path\n",
    "    origin_data_path: str\n",
    "    processed_data_path:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ard.constants import *\n",
    "from src.ard.utils.help import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_preparation_config(self) -> DataPreparationConfig:\n",
    "        config = self.config.data_preparation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_preparation_config = DataPreparationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            origin_data_path=config.origin_data_path,\n",
    "            processed_data_path=config.processed_data_path,\n",
    "        )\n",
    "\n",
    "        return data_preparation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from ard.utils.common import to_categorical\n",
    "from ard.utils.dataset import SeqDataset\n",
    "import logging\n",
    "from ard import logger\n",
    "from operator import itemgetter\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "class DataPreparation:\n",
    "    def __init__(self,\n",
    "                 config : DataPreparationConfig\n",
    "    ):\n",
    "        self.config=config\n",
    "        self._origin_data_path = self.config.origin_data_path\n",
    "        self._processed_data_path = self.config.processed_data_path\n",
    "    def load_npz_data(self, data_path):\n",
    "        \"\"\"\n",
    "        Load data from an NPZ file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the NPZ file.\n",
    "\n",
    "        Returns:\n",
    "            SeqDataset: Loaded dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = np.load(data_path, allow_pickle=True)\n",
    "           \n",
    "            features, targets, lengths, classes = itemgetter('features', 'targets', 'lengths','classes')(data)\n",
    "            idx = np.argwhere(np.isin(targets, classes)).flatten()\n",
    "            ranges = SeqDataset._get_idxs(lengths)[idx]\n",
    "        \n",
    "            return SeqDataset(\n",
    "                features = np.vstack(np.array([x for x in SeqDataset._iter_X(features, ranges)], dtype=object)),\n",
    "                targets = targets[idx],\n",
    "                lengths= lengths[idx],\n",
    "                classes=classes)\n",
    "        \n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading NPZ file: {e}\")\n",
    "            raise\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepare data for a CNN model.\n",
    "\n",
    "        Args:\n",
    "            dataset (SeqDataset): The dataset to prepare.\n",
    "            train_shape (tuple): The desired shape for training data.\n",
    "            test_shape (tuple): The desired shape for testing data.\n",
    "\n",
    "        Returns:\n",
    "            tuple: X_train, X_test, y_train, y_test\n",
    "        \"\"\"\n",
    "        logger.info(\"Loading data from NPZ file...\")\n",
    "        dataset = self.load_npz_data(self._origin_data_path)\n",
    "        logger.info(f\"Dataset loaded\")\n",
    "        X = dataset._features\n",
    "        y = dataset._targets\n",
    "        # Split the data\n",
    "        logger.info(\"Preparing data for training...\")\n",
    "        train_data, test_data = dataset.split_data(split_size=0.2, shuffle=True, stratify=True)\n",
    "        X_train, y_train,_,_ = train_data._get_data()\n",
    "        X_test, y_test,_,_ = test_data._get_data()\n",
    "        \n",
    "        # Reshape for CNN (add channel dimension)\n",
    "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        \n",
    "\n",
    "        # Convert labels to categorical\n",
    "        num_classes = len(np.unique(y))\n",
    "        #y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "        #y_test = to_categorical(y_test,  num_classes=num_classes)\n",
    "        logger.info(f\"Training data shape: {X_train.shape}\")\n",
    "        logger.info(f\"Testing data shape: {X_test.shape}\")\n",
    "        logger.info(f\"Training labels shape: {y_train.shape}\")\n",
    "        logger.info(f\"Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "def pad_sequences(sequences, maxlen):\n",
    "    \"\"\"\n",
    "    Pad or truncate sequences to a specific length.\n",
    "\n",
    "    Args:\n",
    "        sequences (list): List of sequences.\n",
    "        maxlen (int): Desired length of sequences.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Padded sequences.\n",
    "    \"\"\"\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) > maxlen:\n",
    "            padded_sequences.append(seq[:maxlen])\n",
    "        else:\n",
    "            padded_sequences.append(np.pad(seq, ((0, maxlen - len(seq)), (0, 0)), mode='constant'))\n",
    "    return np.array(padded_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 08:35:27,009: INFO: help: yaml file: config\\config.yaml loaded successfully. Content size: 4]\n",
      "[2024-08-09 08:35:27,014: INFO: help: Total directories created: 1]\n",
      "[2024-08-09 08:35:27,019: INFO: help: Total directories created: 1]\n",
      "[2024-08-09 08:35:27,021: INFO: 1094416712: Loading data from NPZ file...]\n",
      "[2024-08-09 08:35:27,211: INFO: 1094416712: Dataset loaded]\n",
      "[2024-08-09 08:35:27,215: INFO: 1094416712: Preparing data for training...]\n",
      "[2024-08-09 08:35:27,225: INFO: 1094416712: Training data shape: (321, 13, 1)]\n",
      "[2024-08-09 08:35:27,227: INFO: 1094416712: Testing data shape: (81, 13, 1)]\n",
      "[2024-08-09 08:35:27,229: INFO: 1094416712: Training labels shape: (321,)]\n",
      "[2024-08-09 08:35:27,230: INFO: 1094416712: Testing labels shape: (81,)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_preparation_config = config.get_data_preparation_config()\n",
    "    data_preparation = DataPreparation(config=data_preparation_config)\n",
    "    X_train, X_test, y_train, y_test = data_preparation.prepare_data()\n",
    "    #dataset.save(compress=True)\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.84621406],\n",
       "        [ 2.68434405],\n",
       "        [ 0.71497554],\n",
       "        [ 0.08256976],\n",
       "        [-0.29053208],\n",
       "        [-0.18529031],\n",
       "        [-0.02732126],\n",
       "        [ 0.16135539],\n",
       "        [ 0.18251677],\n",
       "        [-0.05077429],\n",
       "        [-0.05610316],\n",
       "        [-0.11398745],\n",
       "        [ 0.02956609]]),\n",
       " 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 13)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               7168      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155594 (607.79 KB)\n",
      "Trainable params: 155594 (607.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "11/11 [==============================] - 3s 50ms/step - loss: 4.5598 - accuracy: 0.0997 - val_loss: 3.1025 - val_accuracy: 0.0988\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 2.9465 - accuracy: 0.1153 - val_loss: 2.6648 - val_accuracy: 0.0988\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.5575 - accuracy: 0.1059 - val_loss: 2.4533 - val_accuracy: 0.0988\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.4118 - accuracy: 0.0997 - val_loss: 2.3605 - val_accuracy: 0.1111\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 2.3470 - accuracy: 0.1090 - val_loss: 2.3232 - val_accuracy: 0.1111\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.3208 - accuracy: 0.1059 - val_loss: 2.3097 - val_accuracy: 0.1111\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 2.3090 - accuracy: 0.1153 - val_loss: 2.2999 - val_accuracy: 0.1111\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.3034 - accuracy: 0.1028 - val_loss: 2.2968 - val_accuracy: 0.1235\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 2.3016 - accuracy: 0.1153 - val_loss: 2.2958 - val_accuracy: 0.1235\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.2986 - accuracy: 0.0997 - val_loss: 2.2942 - val_accuracy: 0.1111\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 2.2963 - accuracy: 0.1059 - val_loss: 2.2936 - val_accuracy: 0.1111\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.2980 - accuracy: 0.1059 - val_loss: 2.2944 - val_accuracy: 0.1111\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 2.2949 - accuracy: 0.1121 - val_loss: 2.2934 - val_accuracy: 0.1235\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.2956 - accuracy: 0.1121 - val_loss: 2.2928 - val_accuracy: 0.1111\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.2983 - accuracy: 0.1059 - val_loss: 2.2934 - val_accuracy: 0.1111\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.2922 - accuracy: 0.1059 - val_loss: 2.2935 - val_accuracy: 0.1111\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.2979 - accuracy: 0.1059 - val_loss: 2.2933 - val_accuracy: 0.1111\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.2975 - accuracy: 0.1059 - val_loss: 2.2929 - val_accuracy: 0.1111\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 2.2958 - accuracy: 0.1059 - val_loss: 2.2929 - val_accuracy: 0.1235\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.2964 - accuracy: 0.1246 - val_loss: 2.2927 - val_accuracy: 0.1235\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.2942 - accuracy: 0.1277 - val_loss: 2.2934 - val_accuracy: 0.1235\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 2.2947 - accuracy: 0.1277 - val_loss: 2.2931 - val_accuracy: 0.1235\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.2943 - accuracy: 0.1277 - val_loss: 2.2934 - val_accuracy: 0.1235\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.2950 - accuracy: 0.1277 - val_loss: 2.2935 - val_accuracy: 0.1235\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.2959 - accuracy: 0.1277 - val_loss: 2.2940 - val_accuracy: 0.1235\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.2958 - accuracy: 0.1277 - val_loss: 2.2934 - val_accuracy: 0.1235\n",
      "Epoch 26: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "# Build the model architecture\n",
    "model = keras.Sequential([\n",
    "                          #input layer\n",
    "                          \n",
    "                          keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "                          keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                          keras.layers.Dropout(0.3),\n",
    "                          keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                          keras.layers.Dropout(0.25),\n",
    "                          keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "                          keras.layers.Dropout(0.2),\n",
    "                          keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Callback\n",
    "callback = keras.callbacks.EarlyStopping(monitor=\"loss\",verbose=2, patience=10)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss = \"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs= 1000,batch_size=32,\n",
    "          callbacks=[callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('ADR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33b437c945823112ab56afd7f45c8922bd92262391bfbcb5501165339d121ef4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
