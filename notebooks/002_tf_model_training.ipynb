{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MyOnlineCourses\\\\ML_Projects\\\\arabic-digits-recognition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTFTrainConfig:\n",
    "    root_dir: Path\n",
    "    dst_path: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ard.constants import *\n",
    "from src.ard.utils.help import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_tf_training_config(self) -> DataTFTrainConfig:\n",
    "        config = self.config.data_tf_training\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_tf_training_config = DataTFTrainConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            dst_path=config.dst_path\n",
    "           \n",
    "        )\n",
    "\n",
    "        return data_tf_training_config, self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from ard import logger\n",
    "from ard.utils.tf_utils import build_dataset, finalize_dataset\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')  # Stop tf WARNINGS\n",
    "\n",
    "\n",
    "class ModelTraining:\n",
    "    def __init__(self, config: DataTFTrainConfig, params: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.params = params\n",
    "        self.labels = params['LABELS']\n",
    "    \n",
    "    \n",
    "    def load_and_preprocess_data(self) -> Tuple[tf.data.Dataset, tf.data.Dataset]:\n",
    "        train_files, val_files = self._read_csv_to_list()\n",
    "        for files in [train_files, val_files]:\n",
    "            self._log_audio_info(files)\n",
    "        return self._create_datasets(train_files, val_files)\n",
    "\n",
    "\n",
    "    def _read_csv_to_list(self):\n",
    "\n",
    "        train_files = pd.read_csv(os.path.join(self.config.root_dir, 'train_metadata.csv'))\n",
    "        val_files = pd.read_csv(os.path.join(self.config.root_dir, 'val_metadata.csv'))\n",
    "        logger.info(f\"Total files: {len(train_files)+ len(val_files)}\")\n",
    "        logger.info(f\"Training files: {len(train_files)} ({len(train_files)/(len(train_files)+ len(val_files)):.2%})\")\n",
    "        logger.info(f\"Validation files: {len(val_files)} ({len(val_files)/(len(train_files)+ len(val_files)):.2%})\")\n",
    "        # Convert the 'path' column to a list\n",
    "        return train_files['path'].tolist(), val_files['path'].tolist()\n",
    "        \n",
    "\n",
    "    def _log_audio_info(self, files, desc=None):\n",
    "        num_samples = len(files)\n",
    "        logger.info(f'Number of total examples in {desc}: {num_samples}')\n",
    "        \n",
    "        monos, stereos = self._count_channels(files)\n",
    "        logger.info(f\"Mono audio files: {len(monos)}, Stereo audio files: {len(stereos)} in {desc} dataset\")\n",
    "\n",
    "       \n",
    "\n",
    "    def _count_channels(self, files):\n",
    "        monos, stereos = [], []\n",
    "        for file in files:\n",
    "            wav_contents = tf.io.read_file(file)\n",
    "            wav, _ = tf.audio.decode_wav(contents=wav_contents)\n",
    "            (monos if wav.shape[1] == 1 else stereos).append(file)\n",
    "        return monos, stereos\n",
    "\n",
    "    def _create_datasets(self, train_files, val_files):\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "        train_ds = build_dataset(train_files, AUTOTUNE)\n",
    "        val_ds = build_dataset(val_files, AUTOTUNE)\n",
    "\n",
    "        return finalize_dataset(train_ds, AUTOTUNE), finalize_dataset(val_ds, AUTOTUNE)\n",
    "\n",
    "   \n",
    "    def build_and_train_model(self, train_ds, val_ds):\n",
    "        input_shape = self._get_input_shape(train_ds)[1:]\n",
    "        logger.info(f'Input shape: {input_shape}')\n",
    "        model = self._create_model(input_shape, len(self.params.LABELS))\n",
    "        self._compile_model(model)\n",
    "        self._train_model(model, train_ds, val_ds)\n",
    "\n",
    "        model.save(self.config.dst_path)\n",
    "\n",
    "    def _get_input_shape(self, dataset):\n",
    "        for spectrogram, _ in dataset.take(1):\n",
    "            input_shape = spectrogram.shape\n",
    "        return input_shape\n",
    "\n",
    "    def _create_model(self, input_shape, num_labels):\n",
    "        return tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=input_shape),\n",
    "            tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(num_labels)\n",
    "        ])\n",
    "\n",
    "    def _compile_model(self, model):\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    def _train_model(self, model, train_ds, val_ds):\n",
    "        EPOCHS = 100\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(verbose=1, patience=10)\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        return history\n",
    "        \n",
    "    def train(self):\n",
    "        train, validation = self.load_and_preprocess_data()\n",
    "        self.build_and_train_model(train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-11 23:32:28,822: INFO: help: yaml file: config\\config.yaml loaded successfully. Content size: 8]\n",
      "[2024-08-11 23:32:28,834: INFO: help: yaml file: params.yaml loaded successfully. Content size: 7]\n",
      "[2024-08-11 23:32:28,837: INFO: help: Total directories created: 1]\n",
      "[2024-08-11 23:32:28,842: INFO: help: Total directories created: 1]\n",
      "[2024-08-11 23:32:29,923: INFO: 2185098702: Total files: 361]\n",
      "[2024-08-11 23:32:29,925: INFO: 2185098702: Training files: 321 (88.92%)]\n",
      "[2024-08-11 23:32:29,928: INFO: 2185098702: Validation files: 40 (11.08%)]\n",
      "[2024-08-11 23:32:30,101: INFO: 2185098702: Number of total examples in None: 321]\n",
      "[2024-08-11 23:32:32,033: INFO: 2185098702: Mono audio files: 0, Stereo audio files: 321 in None dataset]\n",
      "[2024-08-11 23:32:32,035: INFO: 2185098702: Number of total examples in None: 40]\n",
      "[2024-08-11 23:32:32,192: INFO: 2185098702: Mono audio files: 0, Stereo audio files: 40 in None dataset]\n",
      "[2024-08-11 23:32:45,040: INFO: 2185098702: Train dataset size: 14]\n",
      "[2024-08-11 23:32:45,042: INFO: 2185098702: Validation dataset size: 2]\n",
      "[2024-08-11 23:32:53,485: INFO: 2185098702: Input shape: (77, 129, 1)]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 31s 2s/step - loss: 3.1390 - accuracy: 0.2835 - val_loss: 2.2357 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 24s 2s/step - loss: 1.8893 - accuracy: 0.4455 - val_loss: 1.8546 - val_accuracy: 0.4750\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 24s 2s/step - loss: 1.3758 - accuracy: 0.5545 - val_loss: 1.1281 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.1317 - accuracy: 0.6417 - val_loss: 1.1620 - val_accuracy: 0.6750\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.9081 - accuracy: 0.6978 - val_loss: 0.8510 - val_accuracy: 0.8250\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.7713 - accuracy: 0.7383 - val_loss: 0.8534 - val_accuracy: 0.8250\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.5877 - accuracy: 0.8193 - val_loss: 0.8886 - val_accuracy: 0.7750\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.5034 - accuracy: 0.8536 - val_loss: 0.7951 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4559 - accuracy: 0.8660 - val_loss: 0.9898 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.3891 - accuracy: 0.8816 - val_loss: 1.0189 - val_accuracy: 0.7750\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.3669 - accuracy: 0.9003 - val_loss: 1.0254 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.2451 - accuracy: 0.9315 - val_loss: 1.1265 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.2810 - accuracy: 0.9097 - val_loss: 1.4331 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 0.2618 - accuracy: 0.9377 - val_loss: 1.0938 - val_accuracy: 0.7750\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.2907 - accuracy: 0.9221 - val_loss: 1.1827 - val_accuracy: 0.7750\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 36s 2s/step - loss: 0.2042 - accuracy: 0.9470 - val_loss: 1.1627 - val_accuracy: 0.7250\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.2613 - accuracy: 0.9283 - val_loss: 1.2375 - val_accuracy: 0.7000\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1786 - accuracy: 0.9595 - val_loss: 1.2380 - val_accuracy: 0.7750\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_tf_training_config, data_tf_training_params = config.get_data_tf_training_config()\n",
    "    data_tf_training = ModelTraining(config=data_tf_training_config, params=data_tf_training_params)\n",
    "    data_tf_training.train()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('arabdigs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd9d8875aaa423a5faaee251418e522698c11b85bd3df211ca48675ae00acaaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
