{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MyOnlineCourses\\\\ML_Projects\\\\arabic-digits-recognition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTrainingConfig:\n",
    "    root_dir: Path\n",
    "    origin_data_path: str\n",
    "    dst_path:Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adr.constants import *\n",
    "from adr.utils.help import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_training_config(self) -> DataTrainingConfig:\n",
    "        config = self.config.data_training\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_training_config = DataTrainingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            origin_data_path=config.origin_data_path,\n",
    "            dst_path=config.dst_path\n",
    "        )\n",
    "\n",
    "        return data_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from ard.utils.common import to_categorical\n",
    "from adr.utils.dataset import SeqDataset\n",
    "import logging\n",
    "from adr import logger\n",
    "from operator import itemgetter\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "class DataTraining:\n",
    "    def __init__(self,\n",
    "                 config : DataTrainingConfig\n",
    "    ):\n",
    "        self.config=config\n",
    "        self._origin_data_path = self.config.origin_data_path\n",
    "        self.num_classes = None\n",
    "        self.input_shape=None\n",
    "    def load_npz_data(self, data_path):\n",
    "        \"\"\"\n",
    "        Load data from an NPZ file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the NPZ file.\n",
    "\n",
    "        Returns:\n",
    "            SeqDataset: Loaded dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = np.load(data_path, allow_pickle=True)\n",
    "           \n",
    "            features, targets, lengths, classes = itemgetter('features', 'targets', 'lengths','classes')(data)\n",
    "            logger.info(f\"features shape: {features.shape}\")\n",
    "            idx = np.argwhere(np.isin(targets, classes)).flatten()\n",
    "        \n",
    "            return SeqDataset(\n",
    "                features = features[idx],\n",
    "                targets = targets[idx],\n",
    "                lengths= lengths[idx],\n",
    "                classes=classes)\n",
    "        \n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading NPZ file: {e}\")\n",
    "            raise\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepare data for a CNN model.\n",
    "\n",
    "        Args:\n",
    "            dataset (SeqDataset): The dataset to prepare.\n",
    "            train_shape (tuple): The desired shape for training data.\n",
    "            test_shape (tuple): The desired shape for testing data.\n",
    "\n",
    "        Returns:\n",
    "            tuple: X_train, X_test, y_train, y_test\n",
    "        \"\"\"\n",
    "        logger.info(\"Loading data from NPZ file...\")\n",
    "        dataset = self.load_npz_data(self._origin_data_path)\n",
    "        \n",
    "        logger.info(f\"Dataset loaded\")\n",
    "        X = dataset._features\n",
    "        y = dataset._targets\n",
    "        \n",
    "        # Split the data\n",
    "        logger.info(\"Preparing data for training...\")\n",
    "        train_data, test_data = dataset.split_data(split_size=0.2, shuffle=True, stratify=True)\n",
    "       \n",
    "        X_train, y_train,_,_ = train_data._get_data()\n",
    "        X_test, y_test,_,_ = test_data._get_data()\n",
    "        logger.info(f\"X_train shape: {X_train.shape}\")\n",
    "        logger.info(f\"y_train shape: {y_train.shape}\")\n",
    "        # Reshape for CNN (add channel dimension)\n",
    "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1],X_train.shape[2], 1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],X_test.shape[2] , 1)\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "        # Convert labels to categorical\n",
    "        self.num_classes = len(np.unique(y))\n",
    "        y_train = tf.keras.utils.to_categorical(y_train, num_classes=self.num_classes)\n",
    "        y_test = tf.keras.utils.to_categorical(y_test,  num_classes=self.num_classes)\n",
    "        logger.info(f\"Training data shape: {X_train.shape}\")\n",
    "        logger.info(f\"Testing data shape: {X_test.shape}\")\n",
    "        logger.info(f\"Training labels shape: {y_train.shape}\")\n",
    "        logger.info(f\"Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def build_and_train_model(self, X_train, X_test, y_train, y_test):\n",
    "        model = self._create_model()\n",
    "        self._compile_model(model)\n",
    "        model = self._train_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        #model.save(self.config.dst_path)\n",
    "      \n",
    "\n",
    "    def _create_model(self, filters=32, kernel_size=(3, 3), dense_units=256, dropout_rate=0.2):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(filters, kernel_size, activation='relu', padding='valid', input_shape=self.input_shape),  \n",
    "            layers.MaxPooling2D(2, padding='same'),\n",
    "            layers.Conv2D(128, kernel_size, activation='relu', padding='valid'),\n",
    "            layers.MaxPooling2D(2, padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Conv2D(128, kernel_size, activation='relu', padding='valid'),\n",
    "            layers.MaxPooling2D(2, padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(dense_units, activation='relu'),\n",
    "            layers.Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def _compile_model(self, model):\n",
    "        model.compile(\n",
    "            loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'acc'\n",
    "        )\n",
    "        model.summary()\n",
    "        \n",
    "\n",
    "    def _train_model(self, model, X_train, X_test, y_train, y_test):\n",
    "       \n",
    "        EPOCHS = 100\n",
    "        batch_size = 12\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, \n",
    "                                                          verbose=1, mode='auto',baseline=None,\n",
    "                                                          restore_best_weights=True)\n",
    "        history = model.fit(X_train,y_train ,\n",
    "            validation_data=(X_test,y_test),\n",
    "            epochs=100,\n",
    "            callbacks = [early_stopping],batch_size=batch_size)\n",
    "        return history\n",
    "    \n",
    "    def process(self):\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data()\n",
    "        self.input_shape=X_train.shape[1:]\n",
    "        logger.info(f'Input shape: {self.input_shape}')\n",
    "        self.build_and_train_model( X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # Wrap the model\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-13 17:08:56,088: INFO: help: yaml file: config\\config.yaml loaded successfully. Content size: 9]\n",
      "[2024-08-13 17:08:56,091: INFO: help: Total directories created: 1]\n",
      "[2024-08-13 17:08:56,094: INFO: help: Total directories created: 1]\n",
      "[2024-08-13 17:08:56,097: INFO: 1287824526: Loading data from NPZ file...]\n",
      "[2024-08-13 17:08:56,143: INFO: 1287824526: features shape: (402, 52, 40)]\n",
      "[2024-08-13 17:08:56,150: INFO: 1287824526: Dataset loaded]\n",
      "[2024-08-13 17:08:56,152: INFO: 1287824526: Preparing data for training...]\n",
      "[2024-08-13 17:08:56,160: INFO: 1287824526: X_train shape: (321, 52, 40)]\n",
      "[2024-08-13 17:08:56,162: INFO: 1287824526: y_train shape: (321,)]\n",
      "[2024-08-13 17:08:56,165: INFO: 1287824526: Training data shape: (321, 52, 40, 1)]\n",
      "[2024-08-13 17:08:56,167: INFO: 1287824526: Testing data shape: (81, 52, 40, 1)]\n",
      "[2024-08-13 17:08:56,168: INFO: 1287824526: Training labels shape: (321, 10)]\n",
      "[2024-08-13 17:08:56,170: INFO: 1287824526: Testing labels shape: (81, 10)]\n",
      "[2024-08-13 17:08:56,172: INFO: 1287824526: Input shape: (52, 40, 1)]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 50, 38, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 25, 19, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 23, 17, 128)       36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 9, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 9, 128)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 7, 128)        147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 4, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220,490\n",
      "Trainable params: 220,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - 6s 174ms/step - loss: 2.3064 - acc: 0.1028 - val_loss: 2.2981 - val_acc: 0.1235\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 3s 127ms/step - loss: 2.2964 - acc: 0.1184 - val_loss: 2.2928 - val_acc: 0.1235\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 4s 138ms/step - loss: 2.2831 - acc: 0.1340 - val_loss: 2.2670 - val_acc: 0.1481\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 2.1855 - acc: 0.1838 - val_loss: 2.1454 - val_acc: 0.2099\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 4s 131ms/step - loss: 2.0505 - acc: 0.2087 - val_loss: 2.0354 - val_acc: 0.2716\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 1.9347 - acc: 0.2710 - val_loss: 1.9408 - val_acc: 0.2593\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 1.8552 - acc: 0.3084 - val_loss: 1.7201 - val_acc: 0.3951\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 3s 124ms/step - loss: 1.6545 - acc: 0.3801 - val_loss: 1.6411 - val_acc: 0.4198\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 4s 136ms/step - loss: 1.4561 - acc: 0.4611 - val_loss: 1.4217 - val_acc: 0.4938\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 1.2766 - acc: 0.5732 - val_loss: 1.2200 - val_acc: 0.5432\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 1.1162 - acc: 0.6044 - val_loss: 1.1827 - val_acc: 0.5926\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.9699 - acc: 0.6760 - val_loss: 1.0861 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.7911 - acc: 0.7196 - val_loss: 0.9458 - val_acc: 0.7037\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 3s 127ms/step - loss: 0.6733 - acc: 0.7664 - val_loss: 0.9789 - val_acc: 0.6667\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.5847 - acc: 0.8037 - val_loss: 1.0866 - val_acc: 0.6543\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 0.5800 - acc: 0.8069 - val_loss: 0.8236 - val_acc: 0.7901\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.5136 - acc: 0.8193 - val_loss: 0.7517 - val_acc: 0.7654\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 3s 126ms/step - loss: 0.4383 - acc: 0.8536 - val_loss: 0.7066 - val_acc: 0.8025\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 3s 127ms/step - loss: 0.3022 - acc: 0.9003 - val_loss: 0.7465 - val_acc: 0.8025\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 4s 144ms/step - loss: 0.3036 - acc: 0.9065 - val_loss: 0.7416 - val_acc: 0.7901\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 4s 155ms/step - loss: 0.3085 - acc: 0.9003 - val_loss: 1.0139 - val_acc: 0.6914\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 4s 143ms/step - loss: 0.2424 - acc: 0.9252 - val_loss: 0.8290 - val_acc: 0.7901\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 4s 129ms/step - loss: 0.2289 - acc: 0.9221 - val_loss: 0.6642 - val_acc: 0.8148\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.1705 - acc: 0.9564 - val_loss: 0.7254 - val_acc: 0.8148\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 4s 135ms/step - loss: 0.1522 - acc: 0.9595 - val_loss: 0.8948 - val_acc: 0.7654\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 3s 127ms/step - loss: 0.1655 - acc: 0.9408 - val_loss: 0.6753 - val_acc: 0.8519\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 3s 129ms/step - loss: 0.2445 - acc: 0.9190 - val_loss: 0.7673 - val_acc: 0.8148\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 3s 128ms/step - loss: 0.1545 - acc: 0.9470 - val_loss: 0.7246 - val_acc: 0.8395\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 0.1035 - acc: 0.9813 - val_loss: 0.8323 - val_acc: 0.8272\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 4s 146ms/step - loss: 0.1130 - acc: 0.9657 - val_loss: 0.6663 - val_acc: 0.8642\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.0952 - acc: 0.9782 - val_loss: 0.8163 - val_acc: 0.7531\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 3s 125ms/step - loss: 0.1368 - acc: 0.9439 - val_loss: 0.7551 - val_acc: 0.8148\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0796 - acc: 0.9782Restoring model weights from the end of the best epoch: 23.\n",
      "27/27 [==============================] - 4s 137ms/step - loss: 0.0796 - acc: 0.9782 - val_loss: 0.8350 - val_acc: 0.8272\n",
      "Epoch 33: early stopping\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_training_config = config.get_data_training_config()\n",
    "    data_training = DataTraining(config=data_training_config)\n",
    "    data_training.process()\n",
    "   \n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('arabdigs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd9d8875aaa423a5faaee251418e522698c11b85bd3df211ca48675ae00acaaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
