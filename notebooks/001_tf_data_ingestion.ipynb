{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MyOnlineCourses\\\\ML_Projects\\\\arabic-digits-recognition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTFIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_path: str\n",
    "    dst_path:str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ard.constants import *\n",
    "from src.ard.utils.help import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "       \n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_tf_ingestion_config(self) -> DataTFIngestionConfig:\n",
    "        config = self.config.data_tf_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_tf_ingestion_config = DataTFIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_path=config.source_path,\n",
    "            dst_path=config.dst_path\n",
    "           \n",
    "        )\n",
    "\n",
    "        return data_tf_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import random\n",
    "from ard import logger\n",
    "from ard.utils.tf_utils import build_dataset, finalize_dataset\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')  # Stop tf WARNINGS\n",
    "\n",
    "class DataTFIngestion:\n",
    "    def __init__(self, config: DataTFIngestionConfig):\n",
    "        self.config = config\n",
    "        self.labels = None\n",
    "\n",
    "    def load_and_preprocess_data(self) -> None:\n",
    "        self.labels = self._get_labels()\n",
    "        files = self._read_and_shuffle_files()\n",
    "        return self._split_and_save_files(files)\n",
    "\n",
    "    def _get_labels(self) -> np.ndarray:\n",
    "        labels = np.array(tf.io.gfile.listdir(str(self.config.source_path)))\n",
    "        logger.info(f'Labels: {labels}')\n",
    "        return labels\n",
    "\n",
    "    def _get_shuffled_files(self) -> tf.Tensor:\n",
    "        _files = tf.io.gfile.glob(str(self.config.source_path) + '*/*')\n",
    "        files = tf.random.shuffle(_files)\n",
    "        self._log_audio_info(files)\n",
    "        return files\n",
    "\n",
    "    def _log_audio_info(self, files):\n",
    "        num_samples = len(files)\n",
    "        logger.info(f'Number of total examples: {num_samples}')\n",
    "        \n",
    "        monos, stereos = self._count_channels(files)\n",
    "        logger.info(f\"Mono audio files: {len(monos)}, Stereo audio files: {len(stereos)}\")\n",
    "\n",
    "        for index, item in enumerate(self.labels):\n",
    "            count = len(tf.io.gfile.listdir(Path(self.config.source_path, self.labels[index])))\n",
    "            logger.info(f'Number of examples for {item}: {count}')\n",
    "\n",
    "    def _count_channels(self, files):\n",
    "        monos, stereos = [], []\n",
    "        for file in files:\n",
    "            wav_contents = tf.io.read_file(file)\n",
    "            wav, _ = tf.audio.decode_wav(contents=wav_contents)\n",
    "            (monos if wav.shape[1] == 1 else stereos).append(file)\n",
    "        return monos, stereos\n",
    "    \n",
    "        \n",
    "\n",
    "    def _split_and_save_files(self, files):\n",
    "        total_files = len(files)\n",
    "        train_size = int(0.80 * total_files)\n",
    "        val_size = int(0.10 * total_files)\n",
    "        \n",
    "        train_files = files[:train_size]\n",
    "        val_files = files[train_size:train_size + val_size]\n",
    "        test_files = files[train_size + val_size:]\n",
    "        \n",
    "        \n",
    "        logger.info(f\"Total files: {total_files}\")\n",
    "        logger.info(f\"Training files: {len(train_files)} ({len(train_files)/total_files:.2%})\")\n",
    "        logger.info(f\"Validation files: {len(val_files)} ({len(val_files)/total_files:.2%})\")\n",
    "        logger.info(f\"Testing files: {len(test_files)} ({len(test_files)/total_files:.2%})\")\n",
    "        metadata = self._extract_labels_from_paths(train_files)\n",
    "        self._save_metadata_to_csv(metadata, os.path.join(self.config.dst_path, 'train_metadata.csv'))\n",
    "        metadata = self._extract_labels_from_paths(val_files)\n",
    "        self._save_metadata_to_csv(metadata, os.path.join(self.config.dst_path, 'val_metadata.csv'))\n",
    "        metadata = self._extract_labels_from_paths(test_files)\n",
    "        self._save_metadata_to_csv(metadata, os.path.join(self.config.dst_path, 'test_metadata.csv'))\n",
    "        \n",
    "        logger.info(f\"Training files saved as train_metadata.csv\")\n",
    "        logger.info(f\"Validation files saved as val_metadata.csv\")\n",
    "        logger.info(f\"Testing files saved as test_metadata.csv\")\n",
    "\n",
    "        return \n",
    "    \n",
    "        \n",
    "    def _extract_labels_from_paths(self, file_paths):\n",
    "        metadata = []\n",
    "        i = 0\n",
    "        for file_path in file_paths:\n",
    "            # Get the parent directory name (label)\n",
    "            label = os.path.basename(os.path.dirname(file_path))\n",
    "            # Append the file path and label to the metadata list\n",
    "            metadata.append({\n",
    "                'path': file_path,\n",
    "                'label': label\n",
    "            })\n",
    "            i=i+1\n",
    "        return metadata\n",
    "\n",
    "    def _save_metadata_to_csv(self, metadata, filename):\n",
    "        # Create a DataFrame and save to CSV\n",
    "        df = pd.DataFrame(metadata)\n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "\n",
    "    def _read_and_shuffle_files(self):\n",
    "        # Get a list of all subdirectories in the source path\n",
    "        subdirs = [os.path.join(self.config.source_path, d) for d in os.listdir(self.config.source_path) if os.path.isdir(os.path.join(self.config.source_path, d))]\n",
    "        \n",
    "        # Initialize an empty list to store all file paths\n",
    "        all_files = []\n",
    "        \n",
    "        # Iterate through each subdirectory and collect audio files\n",
    "        for subdir in subdirs:\n",
    "            for filename in os.listdir(subdir):\n",
    "                if filename.endswith('.wav'):  # Adjust this based on your audio file format\n",
    "                    file_path = os.path.join(subdir, filename)\n",
    "                    all_files.append(file_path)\n",
    "        \n",
    "        # Shuffle the list of file paths\n",
    "        random.shuffle(all_files)\n",
    "        \n",
    "        return all_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-11 23:06:45,426: INFO: help: yaml file: config\\config.yaml loaded successfully. Content size: 8]\n",
      "[2024-08-11 23:06:45,437: INFO: help: Total directories created: 1]\n",
      "[2024-08-11 23:06:45,538: INFO: help: Total directories created: 1]\n",
      "[2024-08-11 23:06:45,544: INFO: 329674396: Labels: ['eight' 'five' 'four' 'nine' 'one' 'seven' 'six' 'three' 'two' 'zero']]\n",
      "[2024-08-11 23:06:45,562: INFO: 329674396: Total files: 402]\n",
      "[2024-08-11 23:06:45,564: INFO: 329674396: Training files: 321 (79.85%)]\n",
      "[2024-08-11 23:06:45,566: INFO: 329674396: Validation files: 40 (9.95%)]\n",
      "[2024-08-11 23:06:45,571: INFO: 329674396: Testing files: 41 (10.20%)]\n",
      "[2024-08-11 23:06:45,669: INFO: 329674396: Training files saved as train_metadata.csv]\n",
      "[2024-08-11 23:06:45,671: INFO: 329674396: Validation files saved as val_metadata.csv]\n",
      "[2024-08-11 23:06:45,673: INFO: 329674396: Testing files saved as test_metadata.csv]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_tf_ingestion_config = config.get_data_tf_ingestion_config()\n",
    "    data_tf_ingestion = DataTFIngestion(config=data_tf_ingestion_config)\n",
    "    data_tf_ingestion.load_and_preprocess_data()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('arabdigs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd9d8875aaa423a5faaee251418e522698c11b85bd3df211ca48675ae00acaaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
