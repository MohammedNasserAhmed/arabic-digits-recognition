{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MyOnlineCourses\\\\ML_Projects\\\\arabic-digits-recognition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataAugmentationConfig:\n",
    "    root_dir: Path\n",
    "    src_dst_path: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ard.constants import *\n",
    "from src.ard.utils.help import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_augmentation_config(self) -> DataAugmentationConfig:\n",
    "        config = self.config.data_augmentation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_augmentation_config = DataAugmentationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            src_dst_path=config.src_dst_path\n",
    "        )\n",
    "\n",
    "        return data_augmentation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from ard import logger\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "pnorm = False\n",
    "rnorm = False\n",
    "class DataAugmentation:\n",
    "    def __init__(self, noise_level=0.001, config = DataAugmentationConfig):\n",
    "        self.noise_level = noise_level\n",
    "        self.config = config\n",
    "\n",
    "    def add_noise(self, audio):\n",
    "        \"\"\"Add random noise to the audio signal.\"\"\"\n",
    "    \n",
    "        noise = np.random.randn(len(audio))\n",
    "        augmented_audio = audio + self.noise_level * noise\n",
    "        return augmented_audio\n",
    "\n",
    "    def peak_normalization(self, audio):\n",
    "        \"\"\"Normalize the audio signal to have a peak amplitude of 1.0.\"\"\"\n",
    "        peak = np.max(np.abs(audio))\n",
    "        if peak > 0:\n",
    "            normalized_audio = audio / peak\n",
    "            pnorm = True\n",
    "        else:\n",
    "            normalized_audio = audio\n",
    "            pnorm - False\n",
    "        return normalized_audio\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    def rms_normalization(self, audio, rms_level=-20):\n",
    "        \"\"\"\n",
    "        Normalize the audio signal to a specified RMS level.\n",
    "\n",
    "        Parameters:\n",
    "            audio (np.ndarray): Input audio signal.\n",
    "            rms_level (float): Desired RMS level in dB (default is -20 dB).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Normalized audio signal.\n",
    "        \"\"\"\n",
    "        # Ensure audio is a NumPy array\n",
    "        audio = np.asarray(audio)\n",
    "\n",
    "        if len(audio) == 0:\n",
    "            raise ValueError(\"Input audio array is empty.\")\n",
    "\n",
    "        # Calculate the target RMS value\n",
    "        target_rms = 10 ** (rms_level / 20.0)\n",
    "\n",
    "        # Calculate the current RMS of the audio\n",
    "        current_rms = np.sqrt(np.mean(audio**2))\n",
    "\n",
    "        if current_rms != 0:\n",
    "            \n",
    "\n",
    "            # Calculate the normalization factor\n",
    "            normalization_factor = target_rms / current_rms\n",
    "\n",
    "            # Normalize the audio\n",
    "            normalized_audio = audio * normalization_factor\n",
    "\n",
    "            # Clip the normalized audio to avoid distortion\n",
    "            normalized_audio = np.clip(normalized_audio, -1.0, 1.0)\n",
    "            rnorm = True\n",
    "        else:\n",
    "            rnorm=False\n",
    "\n",
    "        return normalized_audio\n",
    " \n",
    "\n",
    "    def fade_out(self, audio, fade_duration=1.0, sr=16000):\n",
    "        \"\"\"Apply a fade-out effect to the audio signal.\"\"\"\n",
    "        window = np.hamming(len(audio))\n",
    "        augmented_sig = window * audio\n",
    "        augmented_sig /= np.mean(np.abs(augmented_sig))\n",
    "        #fade_samples = int(fade_duration * sr)\n",
    "        #fade_out_curve = np.linspace(1, 0, fade_samples)\n",
    "        #if fade_samples < len(audio):\n",
    "        #    audio[-fade_samples:] *= fade_out_curve\n",
    "        return augmented_sig\n",
    "\n",
    "    def change_tone(self, audio, sr, n_steps=2):\n",
    "        \"\"\"Change the tone of the audio signal by shifting pitch.\"\"\"\n",
    "        return librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "    def augment(self, audio_path, output_dir):\n",
    "        \"\"\"Load audio, apply augmentations, and save each result as a new file.\"\"\"\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # Apply augmentations\n",
    "        audio_noisy = self.add_noise(audio)\n",
    "        audio_pnormalized = self.peak_normalization(audio)\n",
    "        audio_rnormalized = self.rms_normalization(audio)\n",
    "        audio_fade_out = self.fade_out(audio)\n",
    "        audio_tone_changed = self.change_tone(audio, sr)\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        sub_dir = os.path.dirname(audio_path)\n",
    "        output_sub_dir = os.path.join(output_dir, os.path.basename(sub_dir))\n",
    "        #os.makedirs(output_sub_dir, exist_ok=True)\n",
    "\n",
    "        # Save the augmented audio files\n",
    "        base_filename = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "        sf.write(os.path.join(output_sub_dir, f'{base_filename}_noisy.wav'), audio_noisy, sr)\n",
    "        if pnorm:\n",
    "            sf.write(os.path.join(output_sub_dir, f'{base_filename}_pnormalized.wav'), audio_pnormalized, sr)\n",
    "        if rnorm:\n",
    "            sf.write(os.path.join(output_sub_dir, f'{base_filename}_rnormalized.wav'), audio_rnormalized, sr)\n",
    "        sf.write(os.path.join(output_sub_dir, f'{base_filename}_fade_out.wav'), audio_fade_out, sr)\n",
    "        sf.write(os.path.join(output_sub_dir, f'{base_filename}_tone_changed.wav'), audio_tone_changed, sr)\n",
    "        #logger.info(f\"File {base_filename.split('/')[-1]} augmentations have been saved !!\")\n",
    "        \n",
    "    def get_files(self):\n",
    "        wav_files = []\n",
    "        for root, _, files in os.walk(self.config.src_dst_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.wav'):\n",
    "                    wav_files.append(os.path.join(root, file))\n",
    "                    \n",
    "        return wav_files\n",
    "        \n",
    "    def load(self):\n",
    "        \"\"\"Process all WAV files in the input directory and its subdirectories.\"\"\"\n",
    "        # Gather all .wav files\n",
    "        wav_files = self.get_files()   \n",
    "        logger.info(f\" Total original files : {len(wav_files)}\")\n",
    "        # Use tqdm to show progress while processing the files\n",
    "        with tqdm(total=len(wav_files), colour=\"green\", desc=\"Augmentation Process: \", \n",
    "                  bar_format=\"{l_bar}{bar} [time spent: {elapsed}]\",\n",
    "                  leave=True) as pbar:\n",
    "                    for audio_path in wav_files:\n",
    "                        self.augment(audio_path, self.config.src_dst_path)\n",
    "                        pbar.update(1)\n",
    "                        time.sleep(0.01)\n",
    "        wav_files = self.get_files() \n",
    "        logger.info(f\" Total files after Augmentation : {len(wav_files)}\")\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-10 12:51:07,939: INFO: help: yaml file: config\\config.yaml loaded successfully. Content size: 5]\n",
      "[2024-08-10 12:51:07,951: INFO: help: yaml file: params.yaml loaded successfully. Content size: 7]\n",
      "[2024-08-10 12:51:07,954: INFO: help: Total directories created: 1]\n",
      "[2024-08-10 12:51:07,957: INFO: help: Total directories created: 1]\n",
      "[2024-08-10 12:51:07,971: INFO: 2446048386:  Total original files : 402]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmentation Process: 100%|\u001b[32m██████████\u001b[0m [time spent: 09:29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-10 13:00:37,169: INFO: 2446048386:  Total files after Augmentation : 1608]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_augmentation_config = config.get_data_augmentation_config()\n",
    "    data_augmentation = DataAugmentation(config=data_augmentation_config)\n",
    "    dataset = data_augmentation.load()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('arabdigs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd9d8875aaa423a5faaee251418e522698c11b85bd3df211ca48675ae00acaaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
